{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "iTDGa86rdzny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image, target_size):\n",
        "    resized_image = cv2.resize(image, target_size)\n",
        "    normalized_image = resized_image.astype('float32') / 255.0\n",
        "    return normalized_image"
      ],
      "metadata": {
        "id": "FAS8yFL0eBl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = '/content/drive/MyDrive/Projeto Bimestral/DataSet/Treino'\n",
        "\n",
        "fruits_classes = ['Acai', 'Acerola', 'Ackee', 'Apple', 'Araza', 'Avocado', 'Bael', 'Banana', 'BayBerry', 'BlueBerry']"
      ],
      "metadata": {
        "id": "TrmJcHr2fIR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_size = (32, 32)\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "for fruit_class in fruits_classes:\n",
        "    class_dir = os.path.join(dataset, fruit_class)\n",
        "    for image_file in os.listdir(class_dir):\n",
        "        image_path = os.path.join(class_dir, image_file)\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = preprocess_image(image, target_size)\n",
        "        images.append(image)\n",
        "        labels.append(fruits_classes.index(fruit_class))"
      ],
      "metadata": {
        "id": "lNsr60hFfcco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "num_classes = len(fruits_classes)\n",
        "train_labels = to_categorical(train_labels, num_classes)\n",
        "test_labels = to_categorical(test_labels, num_classes)"
      ],
      "metadata": {
        "id": "YlB5m8zDf3Qv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(layers.Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Conv2D(16, kernel_size=(5, 5), activation='relu'))\n",
        "model.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(120, activation='relu'))\n",
        "model.add(layers.Dense(84, activation='relu'))\n",
        "model.add(layers.Dense(num_classes, activation='softmax'))"
      ],
      "metadata": {
        "id": "p6cxMYM7gBer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(train_images, train_labels, batch_size=32, epochs=27, validation_data=(test_images, test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUOLiA0kgEyi",
        "outputId": "fce77abd-dab7-4998-df1e-ddfdd1fb22fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/27\n",
            "71/71 [==============================] - 2s 20ms/step - loss: 0.1424 - accuracy: 0.9538 - val_loss: 2.8717 - val_accuracy: 0.5915\n",
            "Epoch 2/27\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.0521 - accuracy: 0.9894 - val_loss: 2.8300 - val_accuracy: 0.6197\n",
            "Epoch 3/27\n",
            "71/71 [==============================] - 1s 21ms/step - loss: 0.0581 - accuracy: 0.9846 - val_loss: 3.2381 - val_accuracy: 0.5880\n",
            "Epoch 4/27\n",
            "71/71 [==============================] - 2s 31ms/step - loss: 0.1203 - accuracy: 0.9679 - val_loss: 2.9380 - val_accuracy: 0.6021\n",
            "Epoch 5/27\n",
            "71/71 [==============================] - 2s 35ms/step - loss: 0.0986 - accuracy: 0.9740 - val_loss: 2.8819 - val_accuracy: 0.6215\n",
            "Epoch 6/27\n",
            "71/71 [==============================] - 2s 33ms/step - loss: 0.0260 - accuracy: 0.9960 - val_loss: 2.9012 - val_accuracy: 0.6268\n",
            "Epoch 7/27\n",
            "71/71 [==============================] - 2s 24ms/step - loss: 0.0220 - accuracy: 0.9974 - val_loss: 3.1176 - val_accuracy: 0.6109\n",
            "Epoch 8/27\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.0840 - accuracy: 0.9762 - val_loss: 3.0326 - val_accuracy: 0.6074\n",
            "Epoch 9/27\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.0706 - accuracy: 0.9771 - val_loss: 3.1788 - val_accuracy: 0.5704\n",
            "Epoch 10/27\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.0659 - accuracy: 0.9811 - val_loss: 3.0568 - val_accuracy: 0.6127\n",
            "Epoch 11/27\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.0613 - accuracy: 0.9833 - val_loss: 3.1277 - val_accuracy: 0.6021\n",
            "Epoch 12/27\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.0892 - accuracy: 0.9740 - val_loss: 3.2346 - val_accuracy: 0.5968\n",
            "Epoch 13/27\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.1189 - accuracy: 0.9621 - val_loss: 3.1435 - val_accuracy: 0.5898\n",
            "Epoch 14/27\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.0446 - accuracy: 0.9890 - val_loss: 3.1186 - val_accuracy: 0.6074\n",
            "Epoch 15/27\n",
            "71/71 [==============================] - 2s 22ms/step - loss: 0.0102 - accuracy: 0.9996 - val_loss: 3.2865 - val_accuracy: 0.6144\n",
            "Epoch 16/27\n",
            "71/71 [==============================] - 2s 31ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 3.3530 - val_accuracy: 0.6180\n",
            "Epoch 17/27\n",
            "71/71 [==============================] - 2s 26ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 3.4216 - val_accuracy: 0.6180\n",
            "Epoch 18/27\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 3.5059 - val_accuracy: 0.6197\n",
            "Epoch 19/27\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.5322 - val_accuracy: 0.6197\n",
            "Epoch 20/27\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.5595 - val_accuracy: 0.6268\n",
            "Epoch 21/27\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.6283 - val_accuracy: 0.6232\n",
            "Epoch 22/27\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.6682 - val_accuracy: 0.6250\n",
            "Epoch 23/27\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.6965 - val_accuracy: 0.6197\n",
            "Epoch 24/27\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.7110 - val_accuracy: 0.6232\n",
            "Epoch 25/27\n",
            "71/71 [==============================] - 2s 22ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.7693 - val_accuracy: 0.6250\n",
            "Epoch 26/27\n",
            "71/71 [==============================] - 2s 32ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.7855 - val_accuracy: 0.6197\n",
            "Epoch 27/27\n",
            "71/71 [==============================] - 2s 26ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.8192 - val_accuracy: 0.6144\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb2b8d2b010>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('lenet_model.h5')"
      ],
      "metadata": {
        "id": "etKR3Tq0hV1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = tf.keras.models.load_model('lenet_model.h5')"
      ],
      "metadata": {
        "id": "uL3_UoZOhsNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_single_image(image_path, target_size):\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = preprocess_image(image, target_size)\n",
        "    return image\n",
        "\n",
        "imagem_nova = '/content/drive/MyDrive/Projeto Bimestral/DataSet/imagem_nova/BlueBerry_320.jpg'\n",
        "\n",
        "nova_imagem = preprocess_single_image(imagem_nova, target_size)\n",
        "\n",
        "nova_imagem = np.expand_dims(nova_imagem, axis=0)\n",
        "\n",
        "predictions = loaded_model.predict(nova_imagem)\n",
        "predicted_class_index = np.argmax(predictions)\n",
        "predicted_class = fruits_classes[predicted_class_index]\n",
        "\n",
        "print(\"Classe prevista:\", predicted_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qajhJLyIhysM",
        "outputId": "f88cba66-7ef3-4b1b-b78b-3be2146d8b84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 107ms/step\n",
            "Nova imagem: /content/drive/MyDrive/Projeto Bimestral/DataSet/imagem_nova/BlueBerry_320.jpg\n",
            "Classe prevista: BlueBerry\n"
          ]
        }
      ]
    }
  ]
}